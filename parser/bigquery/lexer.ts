// generated by Textmapper; DO NOT EDIT

import { TextDecoder, TextEncoder } from 'util';
import * as token from './token';
import * as lt from './lexer_tables';

// Lexer states.
const StateInitial = 0;
const StateDotIdentifier = 1;
const StateInTemplatedType = 2;
const StateInBetween = 3;

const bomSeq = "\xef\xbb\xbf";


// soft keywords can be used as identifier (unreserved keywords)
const softKeywordStart = token.TokenType.ABORT;
const softKeywordEnd = token.TokenType.ZONE + 1;

// isSoft returns true when a given token is a `soft keyword` a.k.a. `unreserved keywordâ€œ.
// An identifier name can be a soft keyword.
function isSoft(tok: token.TokenType) : boolean {
  return tok >= softKeywordStart && tok < softKeywordEnd;
}

function decodeRune(str: string, offset: number): { rune: number; size: number } {
  if (offset >= str.length) {
    return { rune: -1, size: 0 };
  }

  const decoder = new TextDecoder('utf-8');
  const remainingString = str.substring(offset); // Create a new string starting from the offset
  const byteArray = new TextEncoder().encode(remainingString); // Encode the string to a Uint8Array
  const decoded = decoder.decode(byteArray);

  if (decoded.length === 0) {
    return { rune: -1, size: 0 };
  }

  const firstChar = decoded.codePointAt(0)!;

  // Determine the size in bytes of the first character
  let size = 1;
  if (firstChar >= 0x80) {
    if (firstChar >= 0x800) {
      if (firstChar >= 0x10000) {
        size = 4
      } else {
        size = 3
      }
    } else {
      size = 2
    }
  }

  return { rune: firstChar, size: size };
}
// Lexer uses a generated DFA to scan through a utf-8 encoded input string. If
// the string starts with a BOM character, it gets skipped.
export class Lexer {
  _source: string;
  _ch: number;           // current character, -1 means EOI
  _offset: number;       // character offset
  _tokenOffset: number;  // last token byte offset
  _line: number;         // current line number (1-based)
  _tokenLine: number;    // last token line
  _scanOffset: number;   // scanning offset
  _value: any;

  _state: number;           // lexer state, modifiable

  // Stack of start conditions to support dotIdentifier, inBetween or
  // inArrayOrStruct. E.g. when we have '<' after 'ARRAY' keyword then parser
  // should enter a separate mode after encountering '<' till it hits a '>'
  // token. `stack` holds all the state/start conditions, except the current
  // which is in State.
  _stack: number[];
  _previousToken: token.TokenType;

  // Initialize the lexer
  constructor(source: string) {
    this._source = source;
    this._ch = 0;
    this._offset = 0;
    this._tokenOffset = 0;
    this._line = 1;
    this._tokenLine = 1;
    this._state = 0

    this._stack = [];
    this._previousToken = token.TokenType.UNAVAILABLE;

    if (source.startsWith(bomSeq)) {
      this._offset += bomSeq.length;
    }
    this.rewind(this._offset)
  }

  // rewind can be used in lexer actions to accept a portion of a scanned token, or to include
  // more text into it.
  private rewind(offset: number) {
    if (offset < this._offset) {
      this._line -= (this._source.substring(offset, this._offset).match(/\n/g) || []).length;
    } else {
      if (offset > this._source.length) {
        offset = this._source.length;
      }
      this._line += (this._source.substring(this._offset, offset).match(/\n/g) || []).length;
    }

    // Scan the next character.
    this._scanOffset = offset;
    this._offset = offset;
    if (this._offset < this._source.length) {
    this._ch = this._source.charCodeAt(this._offset);
    this._scanOffset++
    } else {
      this._ch = -1; // EOI
    }
  }

  // next finds and returns the next token in l.source. The source end is
  // indicated by token.TokenType.EOI.
  //
  // The token text can be retrieved later by calling the text() method.
  next(): token.TokenType {
    restart: while(true) {
      this._tokenLine = this._line;
      this._tokenOffset = this._offset;

      let state = lt.tmStateMap[this._state];
      let backupRule = -1;
      let backupOffset = 0;
      for (; state >= 0; ) {
        let ch = 0;
        if (this._ch >= 0 && this._ch < lt.tmRuneClassLen) {
          ch = lt.tmRuneClass[this._ch];
        } else if (this._ch < 0) {
          state = lt.tmLexerAction[state * lt.tmNumClasses];
          if (state > lt.tmFirstRule && state < 0) {
            state = (-1 - state) * 2;
            backupRule = lt.tmBacktracking[state];
            backupOffset = this._offset;
            state = lt.tmBacktracking[state + 1];
          }
          continue;
        } else {
          ch = 1;
        }
        state = lt.tmLexerAction[state * lt.tmNumClasses + ch];
        if (state > lt.tmFirstRule) {
          if (state < 0) {
            state = (-1 - state) * 2;
            backupRule = lt.tmBacktracking[state];
            backupOffset = this._offset;
            state = lt.tmBacktracking[state + 1];
          }
          if (this._ch === '\n'.charCodeAt(0)) {
            this._line++;
          }
          // Scan the next character.
          // Note: the following code is inlined to avoid performance implications.
          this._offset = this._scanOffset;
          if (this._offset < this._source.length) {
            this._ch = this._source.charCodeAt(this._offset);
            this._scanOffset++;
          } else {
            this._ch = -1; // EOI
          }
        }
      }
      let rule = lt.tmFirstRule - state;
      recovered: while (true) {
        let tok = lt.tmToken[rule];
        let space = false;
        switch (rule) {
          case 0: // no match
    // handleInvalidToken
    if (backupRule >= 0) {
      rule = backupRule;
      this.rewind(backupOffset);
    } else if (this._offset === this._tokenOffset) {
      if (this._ch === -1) {
        tok = token.TokenType.EOI;
      }
      this.rewind(this._scanOffset);
    }
    if (rule !== 0) {
      continue recovered;
    }
    // End handleInvalidToken
          break;
          case 4: // AND_FOR_BETWEEN: /and/
{
    this.pop();
}
          break;
          case 12: // 'BETWEEN': /between/
{
     this.push(StateInBetween);
}
          break;
          case 303: // script_label: /{identifier}{opt_whitespace}[:]{opt_whitespace}(begin|while|loop|repeat|for)/
{
    this.rewind(backupOffset)  // assuming we will backtrack to "identifier_in_lexer"
}
          break;
          case 308: // floating_point_literal: /{floating_point_literal}/
{
    if (this.isAtDotAfterClosingBracketOrSoftKeyword()) {
      this.rewind(this._tokenOffset + 1);
      this.push(StateDotIdentifier);
      tok = token.TokenType.DOT;
    }
}
          break;
          case 309: // invalid_token: /{floating_point_literal}[A-Z_]/
{
    if (this.isAtDotAfterClosingBracketOrSoftKeyword()) {
      this.rewind(this._tokenOffset + 1);
      this.push(StateDotIdentifier);
      tok = token.TokenType.DOT;
    }
}
          break;
          case 311: // identifier_in_lexer: /{generalized_identifier}/
{
    this.pop();
}
          break;
          case 312: // catch_all: /[\x00-\xff]/
            space = true
{
    this.rewind(this._tokenOffset);
    this.pop();
}
          break;
          case 313: // whitespace_no_comments: /{whitespace_no_comments}/
            space = true
          break;
          case 322: // '.': /\./
{
    if (this.isAtDotAfterClosingBracketOrSoftKeyword()) {
      // When an identifier or unreserved keyword is followed by a dot, always
      // move to <dotIdentifier> lexer state. This can recognize keywords
      // as an identifier.
      this.push(StateDotIdentifier);
    }
}
          break;
          case 324: // '<>': /<>/
{
    if (this._previousToken == token.TokenType.ARRAY || this._previousToken == token.TokenType.STRUCT || this._previousToken == token.TokenType.RANGE) {
      // Match only the '<', and move to the same state that that production would
      // have moved to.
      this.push(StateInTemplatedType);
      this.rewind(this._tokenOffset + 1);
      tok = token.TokenType.LT;
    }
}
          break;
          case 332: // '<': /</
{
    if (this._previousToken == token.TokenType.ARRAY || this._previousToken == token.TokenType.STRUCT || this._previousToken == token.TokenType.RANGE) {
      // Switch to a mode that does not recognize >>. This only works as long as
      // there are no legal "independent" < and > inside array or struct types
      // (i.e., without ARRAY or STRUCT preceding) in the grammar. If there are,
      // then the state pushes and pops would become unbalanced, because ">" pops
      // this state.
      this.push(StateInTemplatedType);
    }
}
          break;
          case 333: // '>': />/
{
    if (this._state == StateInTemplatedType) {
      this.pop();
    }
}
          break;
          case 334: // '{': /\{/
{
    this.push(StateInitial);
}
          break;
          case 335: // '[': /\[/
{
    // These need to suspend special modes such as IN_BETWEEN. This is popped
    // again in the close rule below.
    this.push(StateInitial);
}
          break;
          case 336: // '(': /\(/
{
    // These need to suspend special modes such as IN_BETWEEN. This is popped
    // again in the close rule below.
    this.push(StateInitial);
}
          break;
          case 337: // '}': /\}/
{
    this.popNonInitial(); // popping all InTemplatedType, inBetween and dotIdentifierState
    this.pop(); // pop the initial state introduced by the balancing bracket.
}
          break;
          case 338: // ']': /\]/
{
    this.popNonInitial();
    this.pop();
}
          break;
          case 339: // ')': /\)/
{
    this.popNonInitial();
    this.pop();
}
          break;
          case 356: // open_hint: /@{opt_whitespace}\{/
{ this.rewind(this._tokenOffset + 1); }
          break;
          case 357: // open_integer_hint: /@{opt_whitespace}({decimal_digits}|{hex_integer})/
{ this.rewind(this._tokenOffset + 1); }
          break;
        }
        if (space) {
          continue restart;
        }

        this._previousToken = tok;
        return tok;
      }
    }
  }

  // pos returns the start and end positions of the last token returned by Next().
  pos(): {start: number; end: number} {
    return { start: this._tokenOffset, end: this._offset};
  }

    // line returns the line number of the last token returned by next() (1-based).
  line(): number {
    return this._tokenLine;
  }

  // text returns the substring of the input corresponding to the last token.
  text(): string {
    return this._source.substring(this._tokenOffset, this._offset);
  }

  // source returns the input
  source(): string {
    return this._source;
  }

  // Value returns the value associated with the last returned token.
  value() {
    return this._value;
  }

  // Copy forks the lexer in its current state.
  copy(): Lexer {
    let copy = JSON.parse(JSON.stringify(this))
    return copy as Lexer;
  }

  // isAtDotAfterClosingBracketOrSoftKeyword checks that the current character is a dot and
  // the previous token is either:
  // - a proper identifier [a-zA-Z_][a-zA-Z0-9_] or quote identifier.
  // - or a closing parentheses, a closing bracket or a question mark
  // - or is a soft keyword.
  isAtDotAfterClosingBracketOrSoftKeyword() : boolean {
    if (this._source.charAt(this._tokenOffset) !== '.') {
      return false;
    }
    let prev = this._previousToken;
    return (prev == token.TokenType.IDENTIFIER_IN_LEXER ||
      prev == token.TokenType.RPAREN ||
      prev == token.TokenType.RBRACK ||
      prev == token.TokenType.QUEST ||
      isSoft(prev));
  } 

  push(newState: number) : void {
    this._stack.push(this._state);
    this._state = newState;
  }

  // pop replaces the lexer State with the state at the top of the stack.
  // This is a noop when the stack is empty.
  pop() : void {
    if (this._stack.length === 0) {
      return // Typically, unbalanced (too many closing) brackets will try to pop() an empty stack.
    }
    this._state = this._stack.pop();
  }

  // popNonInitial must be called by } ] and ) to pop non-initial states pushed by an opening bracket.
  popNonInitial() : void {
    while (this._state !== StateInitial && this._stack.length > 0) {
      this.pop();
    }
  }

};
