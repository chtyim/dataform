// generated by Textmapper; DO NOT EDIT

import * as common from './common';
import * as token from './token';
import * as lexer from './lexer';
import * as listener from './listener';


// TokenStream post-processes lexer output for consumption by the parser.
export class TokenStream {
  _lexer: lexer.Lexer;
  _listener: listener.Listener; // for ingesting tokens into the AST, nil during lookaheads
  _pending: common.Symbol[];
  constructor(content: string, l: listener.Listener) {
    this._lexer = new lexer.Lexer(content);
    this._listener = l;

    this._pending = [];
  }

  copy(): TokenStream {
    let copy = JSON.parse(JSON.stringify(this))
    return copy as TokenStream;
  }

  private reportIgnored(tok: common.Symbol) : void {
    let t: listener.NodeType;
    switch (tok.symbol) {
      case token.TokenType.LINE_COMMENT:
        t = listener.NodeType.LineComment;
        break;
      case token.TokenType.BLOCK_COMMENT:
        t = listener.NodeType.BlockComment;
        break;
      case token.TokenType.INVALID_TOKEN:
        t = listener.NodeType.InvalidToken;
        break;
      default:
        return;
    }
    if (common.debugSyntax) {
      common.debugLog("ignored:", token.TokenType[tok.symbol], "as", t);
    }
    this._listener(t, 0, tok.offset, tok.endoffset);
  }

  // flush is called for every "shifted" token to report it together with any pending tokens
  // to the listener.
  flush(sym: common.Symbol) : void {
    if (this._listener === null || this._listener === undefined) {
      return;
    }
    let flushed = false;
    if (this._pending.length > 0) {
      for (let i = 0; i < this._pending.length; i++) {
        let tok = this._pending[i];
        if (tok.endoffset > sym.endoffset) {
          // Note: this copying should not happen during normal operation, only
          // during error recovery.
          this._pending = this._pending.slice(i);
          flushed = true;
          break;
        }
        this.reportIgnored(tok);
      }
      if (!flushed) {
        this._pending = [];
      }
    }
    switch (sym.symbol) {
      case token.TokenType.MACRO_ARGUMENT_REFERENCE:
        this._listener(listener.NodeType.KwMacroArgRef, 0, sym.offset, sym.endoffset);
        break;
    }
  }

  text(sym: common.Symbol) : string {
    return this._lexer.source().substring(sym.offset, sym.endoffset);
  }

  line() : number {
    return this._lexer.line();
  }

  pending() : common.Symbol[] {
    return this._pending;
  }

  // next transforms the lexer stream into a stream of symbols for the parser.
  //
  // Note: "stack" and "endState" are nil and -1 respectively during lookaheads
  // and error recovery.
  next(stack: common.StackEntry[], endState: number) : common.Symbol {
    restart: while (true) {
      let tok = this._lexer.next();
      switch (tok) {
        case token.TokenType.LINE_COMMENT:
        case token.TokenType.BLOCK_COMMENT:
        case token.TokenType.INVALID_TOKEN:
          let { start, end } = this._lexer.pos();
          this._pending.push(new common.Symbol(tok, start, end));
          continue restart;
      }
      let { start, end } = this._lexer.pos();
      return new common.Symbol(tok, start, end);
    }
  }

}

